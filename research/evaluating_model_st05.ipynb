{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "from src.ImageClassifier.Constants import *\n",
    "from src.ImageClassifier.Exception import CustomException\n",
    "from src.ImageClassifier.loggers import logger\n",
    "from src.ImageClassifier.Utils import Save_Model,write_json_file,Create_Directory,read_yaml_file\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3) updating the entity file \n",
    "#entity file is nothing but we r defining the parameter as class variable which is used in this evaluating model stage\n",
    "\n",
    "@dataclass\n",
    "class EvaluatingModelConfig():\n",
    "    trained_model_path:Path\n",
    "    training_data_dir:Path #path where image dataset contain\n",
    "    all_param:dict\n",
    "    batch_size:int\n",
    "    input_shape:list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step4) update the configuration manager file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this file we read the yaml file and assign value to \n",
    "#entity class variable through yaml-->and rtn the functn\n",
    "\n",
    "class ConfigurationManager():\n",
    "    def __init__(self,config_filepath=CONFIG_FILEPATH,param_filepath=PARAM_FILEPATH):\n",
    "        self.config = read_yaml_file(config_filepath)\n",
    "        self.param = read_yaml_file(param_filepath)\n",
    "\n",
    "        #creating artifacts directory\n",
    "        Create_Directory([self.config.artifacts_root])\n",
    "\n",
    "    def get_evaluation_config(self) ->EvaluatingModelConfig:\n",
    "        #local variable\n",
    "        eval = self.config.prepare_training\n",
    "\n",
    "        #creating an object of EvaluatingModelConfig class\n",
    "        eval_model_config = EvaluatingModelConfig(\n",
    "            trained_model_path=eval.trained_model_path,\n",
    "            training_data_dir=eval.training_data_dir,\n",
    "            all_param=self.param,\n",
    "            batch_size=self.param.batch_size,\n",
    "            input_shape=self.param.input_shape\n",
    "        )\n",
    "        return eval_model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step5)update the compoenent file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this component file we create a class and initializing the instance variable to entity class variable\n",
    "#and according to task writing the code\n",
    "\n",
    "class EvaluatingModel():\n",
    "    def __init__(self,eval:EvaluatingModelConfig):\n",
    "        self.eval = eval\n",
    "\n",
    "    #first loading the trained model\n",
    "    def trained_model_load(self):\n",
    "        self.model = tensorflow.keras.models.load_model(\n",
    "            filepath=Path(self.eval.trained_model_path)\n",
    "        )\n",
    "\n",
    "    #2nd method creating ImageDatagenerator for testing data!!\n",
    "    def _test_image_generator(self):\n",
    "        #creating keyword argument for test datageenerator\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale=1.0/255,\n",
    "            validation_split=0.30\n",
    "        )\n",
    "\n",
    "        #dataflow directory keyword argument\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size = self.eval.input_shape[:-1],\n",
    "            interpolation = \"bilinear\",\n",
    "            batch_size = self.eval.batch_size,\n",
    "        )\n",
    "\n",
    "        #creating testdata generator !!\n",
    "        test_generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        #now passing this test_generator to flow from imagae dtaset directory\n",
    "        self.test_datagenerator = test_generator.flow_from_directory(\n",
    "            directory = self.eval.training_data_dir,\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs,\n",
    "            subset=\"validation\"\n",
    "\n",
    "        )\n",
    "\n",
    "    #now evaluating the model\n",
    "    def _evaluating_model(self):\n",
    "        self.trained_model_load() #rtn model in same class\n",
    "        self._test_image_generator() #rtn test dataset in same class\n",
    "        evaluation_results  = self.model.evaluate(self.test_datagenerator)\n",
    "        return evaluation_results\n",
    "\n",
    "    #saving the score of model in json!!\n",
    "    def _saving_score(self):\n",
    "        result = self._evaluating_model()\n",
    "        fileapth = \"score.json\"\n",
    "        data = {\"loss\":result[0],\"accuracy\":result[1]}\n",
    "        write_json_file(filepath=Path(fileapth),data=data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\DL MODEL\\\\ImageClassificationModel'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step6) updating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-13 00:47:32,098]-INFO-66-Reading the YAML file config\\config.yaml\n",
      "[2024-09-13 00:47:32,128]-INFO-69-YAML file read successfully: config\\config.yaml\n",
      "[2024-09-13 00:47:32,163]-INFO-66-Reading the YAML file params.yaml\n",
      "[2024-09-13 00:47:32,167]-INFO-69-YAML file read successfully: params.yaml\n",
      "[2024-09-13 00:47:32,219]-INFO-80-Creating Directory\n",
      "Found 13 images belonging to 2 classes.\n",
      "Found 13 images belonging to 2 classes.\n",
      "3/3 [==============================] - 5s 922ms/step - loss: 0.6421 - accuracy: 0.6154\n",
      "Found 13 images belonging to 2 classes.\n",
      "3/3 [==============================] - 3s 933ms/step - loss: 0.6421 - accuracy: 0.6154\n",
      "Data successfully written to score.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cm = ConfigurationManager()\n",
    "    eval_config = cm.get_evaluation_config()\n",
    "\n",
    "    em = EvaluatingModel(eval=eval_config)\n",
    "\n",
    "    em.trained_model_load()\n",
    "\n",
    "    em._test_image_generator()\n",
    "\n",
    "    em._evaluating_model()\n",
    "\n",
    "    em._saving_score()\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
